{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1K8bUhs-difHmcA1WrTfPuJCva0Y4coZB",
      "authorship_tag": "ABX9TyMdGyQr/B6xcHAqA9cvqzc4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/solvibrain/AI-Agents/blob/main/MultiModalRAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gjyWwmA7UqgN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First Component of Building Multimodal RAG Chat with video Project is to Create Embedding."
      ],
      "metadata": {
        "id": "qJwIkYx1Urac"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-zRxEByNRLM"
      },
      "outputs": [],
      "source": [
        "# Collecting dataset and making file of it.\n",
        "# currently I am testing it with 2-3 Instances\n",
        "\n",
        "import os\n",
        "import requests\n",
        "\n",
        "url1='http://farm3.staticflickr.com/2519/4126738647_cc436c111b_z.jpg'\n",
        "cap1='A motorcycle sits parked across from a herd of livestock'\n",
        "\n",
        "url2='http://farm3.staticflickr.com/2046/2003879022_1b4b466d1d_z.jpg'\n",
        "cap2='Motorcycle on platform to be worked on in garage'\n",
        "\n",
        "url3='http://farm1.staticflickr.com/133/356148800_9bf03b6116_z.jpg'\n",
        "cap3='a cat laying down stretched out near a laptop'\n",
        "\n",
        "\n",
        "# Function to download an image from a URL and save it to a specified path\n",
        "def download_image(url, image_path):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an HTTPError for bad responses\n",
        "        with open(image_path, 'wb') as file:\n",
        "            file.write(response.content)\n",
        "        print(f\"Image downloaded and saved to {image_path}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Failed to download image from {url}: {e}\")\n",
        "\n",
        "# List of image dictionaries\n",
        "images = [\n",
        "    {\n",
        "        'url': url1,\n",
        "        'image_path': '/content/sample_data/images/motorcycle_1.jpg',\n",
        "        'caption':cap1\n",
        "    },\n",
        "    {\n",
        "        'url': url2,\n",
        "        'image_path': '/content/sample_data/images/motorcycle_2.jpg',\n",
        "        'caption': cap2\n",
        "    },\n",
        "    {\n",
        "        'url': url3,\n",
        "        'image_path': '/content/sample_data/images/cat1.jpg',\n",
        "        'caption': cap3\n",
        "    }\n",
        "]\n",
        "\n",
        "# Ensure the directory exists\n",
        "for image in images:\n",
        "    os.makedirs(os.path.dirname(image['image_path']), exist_ok=True)\n",
        "\n",
        "# Iterate over each image dictionary and download the image\n",
        "for image in images:\n",
        "    download_image(image['url'], image['image_path'])\n",
        "\n",
        "print(\"All images have been downloaded and saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "for img in images:\n",
        "    image = Image.open(img['image_path'])\n",
        "    caption = img['caption']\n",
        "    display(image)\n",
        "    display(caption)\n",
        "    print()"
      ],
      "metadata": {
        "id": "JfjsFVPba85M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bridge Tower Embedding Computation .\n",
        "\n",
        "Creating Embedding of Multimodal dataset."
      ],
      "metadata": {
        "id": "czy_qTLsfP5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "# Example 1: Reading and Displaying an Image\n",
        "image = cv2.imread('/content/sample_data/images/cat1.jpg')\n",
        "cv2.imshow('Image', image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Example 2: Converting an Image to Grayscale\n",
        "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "cv2.imshow('Grayscale Image', gray_image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Example 3: Edge Detection using Canny\n",
        "edges = cv2.Canny(gray_image, 100, 200)\n",
        "cv2.imshow('Edges', edges)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Example 4: Face Detection using Haar Cascades\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "for (x, y, w, h) in faces:\n",
        "    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "\n",
        "cv2.imshow('Faces', image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n"
      ],
      "metadata": {
        "id": "YSt1RvupdfM0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}